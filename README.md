# Документация по Скриптам.
Эта документация предоставляет обзор трех скриптов, которые осуществляют сбор информации с различных веб-сайтов и сохраняют ее в файлы JSON. Каждый скрипт выполняет определенную задачу и использует техники веб-скрапинга для извлечения актуальных данных.

## Установка.
Для установки необходимо выполнить следующие шаги:

1. Клонировать репозиторий проекта:
   ``git clone https://github.com/HodzukimaruU/Scripts.git``
2. Установить зависимости:
   ``pip install -r requirements.txt``

## Запуск
1. Для запуска нужно зайти в директорию со скриптами.
2. Активировать виртуальное окружение.
3. Зайти в директорию со скриптом, который хотите запустить и прописать команду: python3 script.py

### Скрипт 1: Получение информации о клиниках Dentalia
Этот скрипт направлен на сбор информации о стоматологических клиниках с веб-сайта https://dentalia.com и сохранение ее в файл JSON.

### Функциональность:
1. Принимает URL ленты, содержащей информацию о стоматологических клиниках.
2. Извлекает данные, такие как название клиники, адрес, номер телефона и рабочие часы.
3. Сохраняет извлеченную информацию в файл JSON с именем dentalia_info.json.

### Скрипт 2: Получение информации о суши-барах
Этот скрипт направлен на сбор информации о суши-барах с веб-сайта https://omsk.yapdomik.ru/ и сохранение ее в файл JSON.

### Функциональность:
1. Принимает список URL-адресов различных местоположений суши-баров.
2. Извлекает данные, такие как название, адрес, номер телефона, координаты и рабочие часы.
3. Сохраняет извлеченную информацию в файл JSON с именем sushi_info.json.

### Скрипт 3: Получение информации о пекарнях
Этот скрипт направлен на сбор информации о пекарнях с веб-сайта https://www.santaelena.com.co и сохранение ее в файл JSON.

### Функциональность:
1. Принимает список URL-адресов различных местоположений ресторанов.
2. Извлекает данные, такие как название, адрес, номер телефона и рабочие часы.
3. Использует отдельный модуль для получения координат для каждого адреса пекарни.
4. Сохраняет извлеченную информацию в файл JSON с именем restaurant_info.json

### Зависимости:
1. requests - для выполнения HTTP-запросов.
2. BeautifulSoup (из bs4) - для парсинга HTML.
3. json - для работы с данными в формате JSON.
4. typing - для типизации данных.
5. re - для работы с регулярными выражениями.
6. tqdm - для отображения индикатора выполнения (используется в модуле извлечения координат).

## Минусы
1. В первом скрипте я нашёл, откуда можно извлечь координаты клиник. Однако для получения данных необходимо было получить API-ключ для отправки запросов к Google Maps API. Попытался зарегистрироваться, но там требовалось привязать карту. Похоже, карты белорусских банков не подходят. Я также попробовал использовать польскую карту, но это тоже не сработало. Думаю, если бы мне удалось получить API-ключ, то вполне бы справился с этой задачей. И так же из-за большой вложенности скрипт долго запускается, немного нужно подождать.
2. В силу нехватки времени и большой занятости не успел разделить бизнес логику и работу с данными на разные модули.
3. В третьем скрипте с адресами не удаётся извлечь все координаты, из-за того, что некоторые адреса этот сервис не пробивает. Думаю, с использованием Google Maps API всё было бы более ровнее, но, как я уже писал, мне не удалось получить API-ключ.

## Лицензия
Этот проект лицензируется по [MIT License]().